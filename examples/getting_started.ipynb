{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Convert your trained models to ONNX format\n"," Dlacc is able to accelerate trained deep learning models. First, you must convert your trained models (pytorch, tensorflow, mxnet, etc) to onnx format. Open Neural Network Exchange (ONNX) is an open standard format for representing machine learning models. ONNX is supported by a community of partners who have implemented it in many frameworks and tools."]},{"cell_type":"markdown","metadata":{},"source":[" ## Pytorch to ONNX\n"," We import pre-trained resnet18 model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n","model.eval()\n"]},{"cell_type":"markdown","metadata":{},"source":[" Then we need to construct an example input. contruct_dummy_input() is a useful function for this. You just need to specify a (list of) valid input(s) and also their corresponding datatype(s)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def contruct_dummy_input(input_shape, input_dtype):\n","    dummy_input = tuple(\n","        [\n","            torch.randn(*v).type(\n","                {\n","                    \"int32\": torch.int32,\n","                    \"int64\": torch.int64,\n","                    \"float32\": torch.float32,\n","                    \"float64\": torch.float64,\n","                }[input_dtype[i]]\n","            )\n","            for i, v in enumerate(input_shape)\n","        ]\n","    )\n","    return dummy_input\n","\n","input_shape = [[10,3,224,224]]\n","input_dtype = [\"float32\"]\n","\n","dummy_input = contruct_dummy_input(input_shape, input_dtype)\n","model.eval()\n","# Export the model\n","torch.onnx.export(\n","    model,  # model being run\n","    dummy_input,  # model input (or a tuple for multiple inputs)\n","    \"resnet18.onnx\",\n","    export_params=True,  # store the trained parameter weights inside the model file\n","    do_constant_folding=True,  # whether to execute constant folding for optimization\n","    verbose=True,\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Parameter configuration\n"," Then we create a global json configuration file. The tool will run optimization process according to this json file."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["config = {\n","    \"job_id\": \"100000\",\n","    \"status\": 0,\n","    \"model_name\" : \"resnet\",\n","    \"model_path\": \"./resnet18.onnx\",\n","    \"platform_type\": 0, \n","    \"model_type\" : 2,\n","    \"target\": \"llvm -mcpu cascadelake\",\n","    \"model_config\":{\n","        \"input_shape\":{\n","            \"input.1\": [10,3,224,224],\n","        },\n","        \"input_dtype\":{\n","            \"input.1\": \"float32\",\n","        }\n","    },\n","    \"tuning_config\": {\n","        \"mode\": \"ansor\",\n","        \"num_measure_trials\": 24,\n","        \"verbose_print\": 0\n","    },\n","    \"tuned_log\":\"\",\n","    \"need_benchmark\": True\n","}\n"]},{"cell_type":"markdown","metadata":{},"source":[" Those fields are :\n"," - job_id : id of the job, random int\n"," - status:\n","     - 0: ready\n","     - 1: import to onnx finished\n","     - 2: ansor tuning finished (time cost overhead, skippable if tunned_log specified)\n","     - 3: compile finished\n","     - 4: job done\n","     - -1: error\n"," - model_name: name of the model\n"," - model_path: path to the model.\n","     - an absolute local path if plateform_type==LOCAL\n","     - a google storage bucket link if plateform_type==GOOGLESTORAGE\n"," - platform_type: type of source platform that stores the model file and input json.\n","\n","     ```python\n","     class PlateformType(enum.IntEnum):\n","     \tLOCAL = 0\n","     \tGOOGLESTORAGE = 1\n","     \tAWSSTORAGE = 2\n","     ```\n","\n"," - model_type: type of model. Only onnx format is supported by now.\n","\n"," ```python\n"," class ModelType(enum.IntEnum):\n","     PT = 0\n","     TF = 1\n","     ONNX = 2\n","     KERAS = 3\n"," ```\n","\n"," - target: target hardware backend information\n"," - model_config\n","     - input_shape: shape of each input. **The first dimension must be batch size.**\n","     - input_dtype: datatype of each input.\n"," - tuning_config: tuning parameter configuration\n","     - mode: string value. ansor or autotvm. Only ansor for now.\n","     - num_measure_trials: an int value. More trials, better performance, more time costs.\n","         - when testing, 10 for a quick execution\n","         - when in production, 20000 for best performance.\n","     - verbose_print: if enbale verbose print\n"," - tuned_log: dev only. Tuning will not be executed if a tuned log is passed.\n"," - error_info: dev only. Exception information raised during execution.\n"," - need_benchmark: bool value. Whether need comparison with the original model."]},{"cell_type":"markdown","metadata":{},"source":[" ## Run optimization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from dlacc.optimum import Optimum\n","import onnx\n","model = onnx.load(\"./resnet18.onnx\")\n","output =[node.name for node in model.graph.output]\n","\n","input_all = [node.name for node in model.graph.input]\n","input_initializer =  [node.name for node in model.graph.initializer]\n","net_feed_input = list(set(input_all)  - set(input_initializer))\n","\n","print('Inputs: ', net_feed_input)\n","print('Outputs: ', output)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[" The optimization process may produce many error massages. This is normal because the optimization engine will try some invalid schedules. You can safely ignore them if the tuning can continue, because these errors are isolated from the main process. After optimization, optimized model, statistics, logs will be saved in ./outputs folder. The optimized model will be saved in ./ouputs/optimized_model folder, containing 3 files, deploy_graph.json, deploy_lib.tar, deploy_param.params. You can reutilize those 3 files later in your own production environment."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optimum = Optimum(\"myresnet\")\n","optimum.run(model, config)\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Load optimized model and make a single prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputs_dict = {}\n","predict_model = optimum.load_model(\"./outputs/optimized_model/\", \"llvm -mcpu cascadelake\")\n","result = predict_model.predict(inputs_dict)\n","print(result)\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"interpreter":{"hash":"445bbfea3ef02096f0fe97be9cb1a80f8484f069eac7d1a16c8d3a61f63cad9a"},"kernelspec":{"display_name":"Python 3.9.12 ('dlaccenv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
